# -*- coding: utf-8 -*-
"""Submission Projek Mechine Learning - sistem rekomdasi film.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kg7v78y2VQiJtPFt3MBntZZRtcM0jBU3

# Laporan Proyek Machine Learning - Sistem Rekomendasi Film
-- Mohammad Harry Khomas Saputra --

# Project Overview

Sistem rekomendasi film telah menjadi elemen penting dalam industri hiburan modern. Sistem ini dirancang untuk memberikan pengalaman yang lebih personal kepada pengguna dengan menyarankan film yang relevan sesuai dengan preferensi mereka. Layanan seperti Netflix, iQIYI, dan WeTV adalah contoh platform yang sukses mengimplementasikan sistem rekomendasi untuk meningkatkan keterlibatan pengguna serta kepuasan pelanggan.

Tantangan dalam menemukan film yang sesuai dengan preferensi pengguna sering kali menjadi kendala, terutama ketika pengguna dihadapkan dengan ribuan pilihan film. Hal ini dapat menyebabkan kelelahan dalam memilih dan mengurangi pengalaman pengguna. Oleh karena itu, pengembangan sistem rekomendasi sangat penting untuk membantu mengatasi masalah ini. Dengan sistem rekomendasi yang baik, pengguna dapat dengan mudah menemukan film yang sesuai dengan selera mereka tanpa harus mencari secara manual.

Proyek ini bertujuan untuk memberikan solusi inovatif melalui penerapan algoritma machine learning yang dapat memahami preferensi pengguna berdasarkan data historis mereka. Sistem ini tidak hanya akan meningkatkan pengalaman pengguna tetapi juga membantu platform film dalam meningkatkan keterlibatan pengguna, memperpanjang durasi penggunaan layanan, dan pada akhirnya meningkatkan loyalitas pelanggan. Dengan pendekatan Content-Based Filtering dan Collaborative Filtering, sistem rekomendasi ini menawarkan fleksibilitas dan relevansi tinggi dalam memenuhi kebutuhan pengguna.

# Business Understanding
**Problem Statements**



*   Bagaimana merekomendasikan film yang sesuai dengan preferensi pengguna berdasarkan data historis?
*   Bagaimana meningkatkan akurasi rekomendasi film?

# Goals

*   Membuat sistem rekomendasi yang memudahkan pengguna dalam mendapatkan rekomendasi film yang relevan berdasarkan data historis dan kategori konten.
*   Meningkatkan akurasi rekomendasi film dengan menerapkan algoritma Content-Based Filtering dan Collaborative Filtering.
*   Mengukur keberhasilan sistem rekomendasi menggunakan metrik evaluasi yang sesuai, seperti precision dan RMSE.

# Solution Approach

1.   Content-Based Filtering:

  *   Memanfaatkan metadata film (genre, deskripsi) untuk memberikan rekomendasi berdasarkan kesamaan dengan film yang disukai pengguna sebelumnya.
2.   Collaborative Filtering:
  *   Menggunakan data historis dari interaksi pengguna untuk merekomendasikan film yang telah disukai pengguna lain dengan pola preferensi serupa.
"""

!pip install opendatasets

from google.colab import files
files.upload()  # Unggah file kaggle.json Anda

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

import opendatasets as od
od.download('https://www.kaggle.com/datasets/rohan4050/movie-recommendation-data')

"""# Data Understanding

# Informasi Dataset

## Dataset terdiri dari empat file utama:
- **links.csv**: Daftar tautan film.
- **movies.csv**: Metadata film (judul, genre).
- **ratings.csv**: Rating yang diberikan oleh pengguna.
- **tags.csv**: Kata kunci terkait film.

## Jumlah Data
- **links.csv**: 9,742 baris dan 3 kolom.
- **movies.csv**: 9,742 baris dan 3 kolom.
- **ratings.csv**: 100,836 baris dan 4 kolom.
- **tags.csv**: 14,531 baris dan 4 kolom.

## Kondisi Data
### Missing Value:
- **tags.csv**: Kolom `tag` memiliki nilai kosong.
- **ratings.csv**: Tidak memiliki nilai kosong.
- **movies.csv** dan **links.csv**: Lengkap tanpa nilai kosong.

### Duplikasi:
- Tidak ditemukan duplikasi pada dataset utama.

### Outlier:
- Skala rating berkisar antara **0.5 hingga 5**, sesuai dengan rentang normal rating pengguna.

## Tautan Sumber Data
Dataset dapat diakses melalui tautan berikut: [Movie Recommendation Dataset](https://www.kaggle.com/datasets/rohan4050/movie-recommendation-data?select=ml-latest-small).

## Uraian Fitur Dataset
### links.csv
- **movieId**: ID unik untuk setiap film.
- **imdbId**: ID film pada platform IMDb.
- **tmdbId**: ID film pada platform TMDb.

### movies.csv
- **movieId**: ID unik untuk setiap film.
- **title**: Judul film.
- **genres**: Kategori genre yang terkait dengan film, dipisahkan oleh tanda `|`.

### ratings.csv
- **userId**: ID unik untuk setiap pengguna.
- **movieId**: ID unik untuk setiap film.
- **rating**: Nilai rating yang diberikan oleh pengguna (0.5 hingga 5).
- **timestamp**: Waktu pemberian rating.

### tags.csv
- **userId**: ID unik untuk setiap pengguna.
- **movieId**: ID unik untuk setiap film.
- **tag**: Tag atau kata kunci yang diberikan oleh pengguna.
- **timestamp**: Waktu pemberian tag.

## Import Library
"""

import pandas as pd
import numpy as np

"""*  pandas: Library untuk manipulasi dan analisis data, termasuk membaca, menulis, dan memproses file berbasis tabel (seperti CSV).
*  numpy: Library untuk operasi numerik yang efisien, sering digunakan untuk perhitungan matematis dalam array.

# Exploratory Data Analysis
## Membaca File CSV
"""

links = pd.read_csv('/content/movie-recommendation-data/ml-latest-small/links.csv')
movies = pd.read_csv('/content/movie-recommendation-data/ml-latest-small/movies.csv')
ratings = pd.read_csv('/content/movie-recommendation-data/ml-latest-small/ratings.csv')
tags = pd.read_csv('/content/movie-recommendation-data/ml-latest-small/tags.csv')

"""## Menampilkan Informasi Dataset

Kode ini digunakan untuk menampilkan informasi detail tentang struktur dataset, seperti jumlah baris, kolom, tipe data, dan apakah terdapat nilai yang hilang (missing values).
"""

print(links.info())
print(movies.info())
print(ratings.info())
print(tags.info())

"""## Analisis Genre pada Dataset Film

Kode ini memisahkan genre, menampilkan setiap genre sebagai baris baru, dan menghitung jumlah kemunculannya. Berikut adalah hasilnya:
"""

genre_counts = movies['genres'].str.split('|').explode().value_counts()
print(genre_counts)

"""## Visualisasi Distribusi Rating

Tahap ini bertujuan untuk memahami distribusi rating yang diberikan pengguna dalam dataset ratings.
"""

ratings['rating'].plot(kind='hist', bins=10, title='Distribusi Rating')

"""Grafik diatas menunjukkan distribusi rating yang diberikan oleh pengguna terhadap film.

# Data Preprocessing
## Mengatasi Missing Value
Langkah ini bertujuan untuk membersihkan dataset dari nilai kosong (missing value) pada kolom yang relevan. Menghapus missing value membantu memastikan analisis data dan pemodelan menjadi lebih akurat.
"""

# Hapus missing value pada dataset
movies_clean = movies.dropna()
ratings_clean = ratings.dropna()
tags_clean = tags.dropna()

print("Jumlah data setelah menghapus missing value:")
print(f"Movies: {len(movies_clean)}")
print(f"Ratings: {len(ratings_clean)}")
print(f"Tags: {len(tags_clean)}")

"""## Menggabungkan Dataset

**Gabungkan data berdasarkan movieId.**

Langkah ini bertujuan untuk menggabungkan beberapa dataset (ratings, movies, dan tags) menjadi satu DataFrame yang utuh. Dataset gabungan ini mempermudah analisis dan pemodelan di tahap selanjutnya.
"""

# Gabungkan data ratings dengan movies
movie_info = pd.merge(ratings_clean, movies_clean[['movieId', 'title', 'genres']], on='movieId', how='left')

# Gabungkan movie_info dengan tags
full_data = pd.merge(movie_info, tags_clean[['movieId', 'tag']], on='movieId', how='left')
full_data = full_data.dropna()  # Hapus nilai kosong setelah penggabungan

print("Data setelah penggabungan:")
print(full_data.head())

"""## Menggabungkan Seluruh Movie ID

Langkah ini bertujuan untuk menggabungkan semua movieId dari keempat dataset (links, movies, ratings, dan tags) agar menghasilkan daftar lengkap ID film yang unik.
"""

# Menggabungkan seluruh movieID
movie_all = np.concatenate((
    links.movieId.unique(),
    movies.movieId.unique(),
    ratings.movieId.unique(),
    tags.movieId.unique(),
))

movie_all = np.sort(np.unique(movie_all))
print('Jumlah data by movieID: ', len(movie_all))

"""## Menggabungkan Seluruh User ID

Langkah ini bertujuan untuk menggabungkan semua userId dari dataset ratings dan tags sehingga menghasilkan daftar lengkap ID pengguna yang unik.
"""

user_all = np.concatenate((
    ratings.userId.unique(),
    tags.userId.unique(),
))

user_all = np.sort(np.unique(user_all))
print('Jumlah data user: ', len(user_all))

"""## Penggabungan Data Menggunakan Concat dan Merge

Menggabungkan data dari beberapa dataset (links, movies, ratings, dan tags) menjadi satu dataset utuh yang berisi informasi lengkap untuk setiap film.
"""

movie_info = pd.concat([links, movies, ratings, tags])
movie = pd.merge(ratings, movie_info , on='movieId', how='left')
movie

"""Memeriksa jumlah nilai kosong (missing value) pada setiap kolom di dataset movie."""

movie.isnull().sum()

"""Dari output di atas, diketahui bahwa dataset hasil penggabungan memiliki jumlah nilai kosong (missing values) yang cukup signifikan di beberapa kolom. Kolom seperti userId_x, movieId, rating_x, dan timestamp_x tidak memiliki nilai kosong, yang berarti data ini lengkap. Namun, kolom seperti imdbId, tmdbId, title, dan genres memiliki lebih dari **6,258,000** nilai kosong, menunjukkan bahwa sebagian besar film tidak memiliki informasi tambahan seperti ID IMDb, ID TMDb, judul, atau genre. Selain itu, kolom seperti userId_y, rating_y, dan timestamp_y juga memiliki ribuan nilai kosong, dengan masing-masing sebanyak **201,672** hingga **434,885** nilai kosong. Kolom tag menunjukkan jumlah nilai kosong terbesar, yaitu **6,126,372**, yang mengindikasikan sebagian besar film tidak memiliki informasi tag yang relevan. Oleh karena itu, langkah data cleaning sangat diperlukan, baik dengan menghapus baris atau kolom yang memiliki banyak nilai kosong, atau menggunakan metode imputasi untuk melengkapi data yang hilang, agar analisis dan pemodelan dapat memberikan hasil yang optimal.

## Mengelompokkan dan Menjumlahkan Data Berdasarkan Movie ID
Langkah ini bertujuan untuk mengelompokkan data berdasarkan kolom movieId dan menjumlahkan nilai pada kolom numerik untuk setiap grup.
"""

movie.groupby('movieId').sum()

"""## Membuat Salinan Data

Pada langkah ini, kita membuat salinan dataset ratings dan menyimpannya dalam variabel baru bernama all_movie_rate.
"""

all_movie_rate = ratings
all_movie_rate

"""## Menggabungkan Dataset Ratings dengan Movies

Langkah ini bertujuan untuk menggabungkan dataset all_movie_rate dengan dataset movies sehingga setiap rating memiliki informasi tambahan seperti judul (title) dan genre (genres) film.
"""

all_movie_name = pd.merge(all_movie_rate, movies[['movieId','title','genres']], on='movieId', how='left')
all_movie_name

"""## Menggabungkan Dataset dengan Tags

Langkah ini bertujuan untuk menggabungkan dataset all_movie_name dengan dataset tags sehingga setiap film memiliki informasi tambahan berupa tag yang diberikan pengguna.
"""

all_movie = pd.merge(all_movie_name, tags[['movieId','tag']], on='movieId', how='left')
all_movie

"""# Data Preparation
## Memeriksa Missing Value dalam Dataset Gabungan

Langkah ini bertujuan untuk memeriksa jumlah nilai kosong (missing value) di setiap kolom dataset all_movie.
"""

all_movie.isnull().sum()

"""## Menghapus Missing Value dalam Dataset

Langkah ini bertujuan untuk menghapus baris yang memiliki nilai kosong (missing value) dalam dataset all_movie, sehingga menghasilkan dataset yang bersih tanpa nilai kosong.
"""

all_movie_clean = all_movie.dropna()
all_movie_clean

"""Periksa kembali jumlah nilai kosong (missing value) di setiap kolom dataset all_movie"""

all_movie_clean.isnull().sum()

"""##Mengurutkan Data Berdasarkan Movie ID

Langkah ini bertujuan untuk mengurutkan dataset all_movie_clean berdasarkan kolom movieId dalam urutan menaik (ascending), sehingga memudahkan analisis atau pemrosesan data lebih lanjut.
"""

fix_movie = all_movie_clean.sort_values('movieId', ascending=True)
fix_movie

"""## Menghitung Jumlah Film Unik

Langkah ini bertujuan untuk menghitung jumlah film unik dalam dataset fix_movie berdasarkan kolom movieId.
"""

len(fix_movie.movieId.unique())

"""## Menyiapkan Dataset untuk Pemrosesan Selanjutnya

Langkah ini bertujuan untuk membuat salinan dataset fix_movie ke variabel baru preparation dan memastikan dataset tetap diurutkan berdasarkan kolom movieId.
"""

preparation = fix_movie
preparation.sort_values('movieId')

"""## Menghapus Duplikasi Data Berdasarkan Movie ID
Langkah ini bertujuan untuk menghapus baris duplikat dalam dataset preparation berdasarkan kolom movieId, sehingga setiap film hanya memiliki satu baris data.
"""

# Membuang data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('movieId')
preparation

"""## Mengonversi Data Series ke Dalam Bentuk List
Langkah ini bertujuan untuk mengubah kolom tertentu dari dataset preparation menjadi list Python agar lebih mudah digunakan dalam pemrosesan lebih lanjut, seperti pemodelan atau analisis.
"""

movie_id = preparation['movieId'].tolist()
movie_name = preparation['title'].tolist()
movie_genre = preparation['genres'].tolist()

print('Jumlah data series movieId: ', len(movie_id))
print('Jumlah data series title: ', len(movie_name))
print('Jumlah data series genres: ', len(movie_genre))

"""## Membuat Dictionary untuk Film
Langkah ini bertujuan untuk membuat DataFrame baru yang merepresentasikan dictionary dari data film, dengan memetakan movie_id, movie_name, dan movie_genre dalam satu struktur data yang rapi.
"""

# Membuat dictionary untuk data ‘movie_id’, ‘movie_name’, dan ‘movie_genre’
movie_new = pd.DataFrame({
    'id': movie_id,
    'movie_name': movie_name,
    'genre': movie_genre
})
movie_new

"""# Modeling and Result

Proses pemodelan yang dilakukan dalam proyek ini melibatkan penerapan dua algoritma machine learning, yaitu **Content-Based Filtering** dan **Collaborative Filtering**. Algoritma Content-Based Filtering digunakan untuk merekomendasikan film berdasarkan preferensi pengguna sebelumnya dengan menganalisis kesamaan karakteristik film yang disukai. Sementara itu, Collaborative Filtering diterapkan untuk memberikan rekomendasi berdasarkan pola interaksi dan penilaian dari pengguna lain yang memiliki preferensi serupa. Pendekatan ini memungkinkan sistem rekomendasi menjadi lebih personal dan relevan.

## Menggunakan TF-IDF untuk Genre Film

Langkah ini bertujuan untuk menghitung TF-IDF (Term Frequency-Inverse Document Frequency) dari kolom genre dalam dataset movie_new. TF-IDF digunakan untuk merepresentasikan genre film dalam bentuk numerik yang dapat diproses oleh model machine learning.
"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data genre
tf.fit(movie_new['genre'])

# Mapping array dari fitur index integer ke fitur nama
feature_names = tf.get_feature_names_out()
print(feature_names)

"""## Menghitung dan Memeriksa Matriks TF-IDF

Langkah ini bertujuan untuk menghitung representasi numerik TF-IDF dari kolom genre dalam dataset movie_new dan memeriksa dimensi (bentuk) matriks yang dihasilkan.
"""

tfidf_matrix = tf.fit_transform(movie_new['genre'])
tfidf_matrix.shape

"""## Mengubah Sparse Matrix TF-IDF Menjadi Dense Matrix
Langkah ini bertujuan untuk mengubah matriks TF-IDF yang dihasilkan dalam format sparse matrix menjadi dense matrix agar lebih mudah dibaca dan divisualisasikan.
"""

tfidf_matrix.todense()

"""## Membuat DataFrame dari Matriks TF-IDF

Langkah ini bertujuan untuk mengubah matriks TF-IDF menjadi DataFrame pandas, sehingga lebih mudah untuk dibaca, dianalisis, dan divisualisasikan.
"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=movie_new['movie_name']
).sample(22, axis=1).sample(10, axis=0)

"""## Menghitung Cosine Similarity

Langkah ini bertujuan untuk menghitung Cosine Similarity antar film berdasarkan nilai TF-IDF dari genre. Cosine Similarity digunakan untuk menentukan tingkat kesamaan antara dua film.


cosine_similarity(tfidf_matrix):

Menghitung Cosine Similarity antar baris dalam matriks TF-IDF (tfidf_matrix).
Cosine Similarity adalah metrik yang mengukur kesamaan antara dua vektor berdasarkan sudut kosinusnya:


$$\text{Cosine Similarity} = \frac{\mathbf{A} \cdot \mathbf{B}}{||\mathbf{A}|| \times ||\mathbf{B}||}$$


Nilai berkisar dari 0 hingga 1:
*  1: Vektor (film) identik.
*  0: Tidak ada kesamaan antara vektor (film).

cosine_sim:

*  Matriks dua dimensi (2D) dengan bentuk (n, n), di mana n adalah jumlah film.
*  Baris dan kolom merepresentasikan film.
*  Setiap elemen [i, j] menunjukkan tingkat kesamaan antara film i dan film j.

"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""## Membuat DataFrame dari Cosine Similarity
Langkah ini bertujuan untuk mengubah matriks Cosine Similarity menjadi DataFrame pandas, sehingga lebih mudah untuk dianalisis dan dimanipulasi.
"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=movie_new['movie_name'], columns=movie_new['movie_name'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""## Membuat Fungsi Rekomendasi Film
Fungsi ini digunakan untuk memberikan rekomendasi film berdasarkan kesamaan (Cosine Similarity) antar film yang dihitung sebelumnya.
"""

def movie_recommendations(nama_movie, similarity_data=cosine_sim_df, items=movie_new[['movie_name', 'genre']], k=5):


    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_movie].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_movie agar nama movie yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_movie, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

movie_new[movie_new.movie_name.eq('Memento (2000)')]

"""Kode ini digunakan untuk memberikan rekomendasi film berdasarkan kesamaan (Cosine Similarity) dengan film 'Jumanji (1995)'."""

movie_recommendations('Memento (2000)')

"""Dari hasil rekomendasi di atas, sistem memberikan lima film yang memiliki kesamaan dengan film "Jumanji (1995)" berdasarkan genre. Film-film yang direkomendasikan memiliki genre yang serupa, yaitu Adventure, Children, dan Fantasy, yang merupakan genre utama dari "Jumanji (1995)"

## Import Library
import library yang diperlukan untuk berbagai tahap dalam proyek, seperti manipulasi data, pembangunan model, dan visualisasi.
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""## Menyimpan Dataset Ratings
Menyimpan dataset ratings ke dalam variabel baru (df) agar lebih mudah diakses dan dimanipulasi selama proses analisis dan pemodelan.
"""

df = ratings
df

"""Dataset ratings terdiri dari **100,836** baris dan 4 kolom: userId, movieId, rating, dan timestamp. Kolom userId merepresentasikan ID unik untuk setiap pengguna, sedangkan kolom movieId adalah ID unik untuk setiap film yang dirating oleh pengguna. Kolom rating mencatat nilai rating yang diberikan oleh pengguna untuk film, dengan rentang nilai dari 0.5 hingga 5.0. Kolom timestamp berisi waktu dalam format UNIX timestamp yang menunjukkan kapan rating tersebut diberikan. Misalnya, pengguna dengan userId 1 memberikan rating 4.0 untuk film dengan movieId 1 pada waktu 964982703, dan rating lain untuk beberapa film berbeda seperti movieId 3 dan movieId 6. Data ini mencakup informasi interaksi antara pengguna dan film yang penting untuk analisis. Kolom rating menjadi kunci utama dalam memahami preferensi pengguna, sementara kolom timestamp dapat digunakan untuk melihat pola perubahan preferensi pengguna seiring waktu. Dataset ini siap untuk digunakan dalam pengembangan sistem rekomendasi, khususnya dengan pendekatan Collaborative Filtering.

## Encoding userId
Langkah ini bertujuan untuk mengubah data userId menjadi bentuk yang lebih mudah diproses dalam model machine learning, yaitu encoding berupa angka.
"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = df['userId'].unique().tolist()
print('list userID: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

"""## Encoding movieId dan Mapping ke DataFrame
Langkah ini bertujuan untuk mengubah data movieId menjadi bentuk numerik yang lebih mudah diproses dalam model machine learning, dan memetakan hasil encoding ke DataFrame.
"""

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = df['movieId'].unique().tolist()

# Melakukan proses encoding movieId
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Melakukan proses encoding angka ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

# Memetakan userId dan movieId ke dataframe yang berkaitan.

# Mapping userId ke dataframe genres
df['genres'] = df['userId'].map(user_to_user_encoded)

# Mapping movieD ke dataframe movies
df['movies'] = df['movieId'].map(movie_to_movie_encoded)

"""## Mengecek Jumlah Pengguna, Film, dan Skala Rating
Langkah ini bertujuan untuk mendapatkan informasi dasar tentang data pengguna, film, dan skala rating yang ada dalam dataset.
"""

num_users = len(user_to_user_encoded)
print(num_users)

num_movie = len(movie_encoded_to_movie)
print(num_movie)

df['ratings'] = df['rating'].values.astype(np.float32)

min_rating = min(df['rating'])

max_rating = max(df['rating'])

print('Number of User: {}, Number of movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""## Mengacak Dataset
Langkah ini bertujuan untuk mengacak urutan data dalam dataset agar data tidak memiliki pola yang berurutan, yang dapat memengaruhi proses pelatihan model.
"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

"""# Menggabungkan Data dan Membagi Dataset
Langkah ini bertujuan untuk mempersiapkan data input (x) dan target output (y) yang akan digunakan dalam proses pelatihan dan validasi model.

Normalisasi Rating dan Pembagian Dataset

## Normalisasi Rating


Rating dinormalisasi menggunakan rumus berikut:

$$
{rating\_baru} = \frac{\text{rating} - {rating\_minimum}}{{rating\_maksimum} - {rating\_minimum}}
$$


Tujuan:
Menyelaraskan nilai rating agar berada pada rentang 0 hingga 1.

Normalisasi ini membantu proses pelatihan model agar lebih stabil dan mudah diinterpretasikan.


## Membagi Dataset
Dataset dibagi menjadi dua bagian utama untuk memastikan performa model dapat dievaluasi dengan baik:

1. 80% Data Pelatihan:

  Digunakan untuk melatih model agar dapat mempelajari pola dari data.

2. 20% Data Validasi:

  Digunakan untuk menguji performa model terhadap data yang belum pernah dilihat model sebelumnya.
Proses pembagian dataset dilakukan berdasarkan indeks data.


"""

# Menggabungkan kolom genres dan movies ke dalam satu variabel x
x = df[['genres', 'movies']].values

# Normalisasi nilai rating ke rentang 0 hingga 1 untuk disimpan dalam variabel y
y = df['ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi dataset menjadi 80% untuk pelatihan dan 20% untuk validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],   # Data pelatihan untuk input
    x[train_indices:],   # Data validasi untuk input
    y[:train_indices],   # Data pelatihan untuk target
    y[train_indices:]    # Data validasi untuk target
)

# Menampilkan hasil akhir variabel x (input data) dan y (target output)
print("Input data (x):", x[:5])  # Menampilkan 5 baris pertama variabel x
print("Target output (y):", y[:5])  # Menampilkan 5 baris pertama variabel y

"""Output data menampilkan 5 baris pertama variabel x, berupa pasangan nilai genres dan movies, serta 5 baris pertama variabel y, berupa rating yang telah dinormalisasi. Dengan data yang telah disiapkan ini, model dapat dilatih untuk memprediksi preferensi pengguna berdasarkan genre dan film yang telah dirating.

## RecommenderNet: Arsitektur Model Sistem Rekomendasi

Kelas RecommenderNet adalah implementasi model sistem rekomendasi menggunakan TensorFlow/Keras. Model ini menggunakan embedding untuk merepresentasikan pengguna dan film dalam ruang vektor berdimensi rendah.
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movie_embedding = layers.Embedding( # layer embeddings movies
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1) # layer embedding movies bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movie_vector = self.movie_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movie_bias = self.movie_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)

    x = dot_user_movie + user_bias + movie_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""## Pelatihan Model

## Inisialisasi dan Kompilasi Model

Kode ini bertujuan untuk menginisialisasi model sistem rekomendasi menggunakan kelas RecommenderNet yang telah didefinisikan sebelumnya, lalu meng-compile model agar siap untuk dilatih.
"""

model = RecommenderNet(num_users, num_movie, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""## Memulai Proses Pelatihan Model
Kode ini digunakan untuk melatih model sistem rekomendasi RecommenderNet menggunakan data pelatihan (x_train, y_train) dan memvalidasi performa model menggunakan data validasi (x_val, y_val).


"""

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 64,
    epochs = 25,
    validation_data = (x_val, y_val)
)

"""Dari hasil pelatihan model selama 25 epoch, terlihat bahwa nilai loss dan root_mean_squared_error (RMSE) pada dataset pelatihan dan validasi mengalami penurunan secara konsisten di beberapa epoch awal, menunjukkan bahwa model sedang belajar dengan baik.

## Visualisasi Performa Model Selama Pelatihan

Kode ini digunakan untuk memvisualisasikan metrik Root Mean Squared Error (RMSE) selama proses pelatihan pada data pelatihan dan validasi.
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Grafik di atas menampilkan tren metrik Root Mean Squared Error (RMSE) untuk data pelatihan (train) dan data validasi (test) selama 25 epoch. Pada data pelatihan, RMSE menunjukkan penurunan yang konsisten seiring bertambahnya jumlah epoch, yang mengindikasikan bahwa model semakin memahami pola data dan mampu memprediksi dengan lebih akurat. Sementara itu, RMSE pada data validasi cenderung stabil setelah beberapa epoch awal, menunjukkan bahwa model tidak mengalami overfitting secara signifikan. Selisih antara RMSE data pelatihan dan validasi juga tetap kecil, menandakan bahwa model memiliki kemampuan generalisasi yang baik terhadap data validasi. Secara keseluruhan, grafik ini menunjukkan bahwa model belajar dengan baik dan mampu memprediksi preferensi pengguna secara efektif dalam sistem rekomendasi film.

## Mendapatkan Rekomendasi
Menyiapkan data yang akan digunakan dalam memberikan rekomendasi film kepada pengguna tertentu
"""

movie_df = movie_new
df = pd.read_csv('movie-recommendation-data/ml-latest-small/ratings.csv')


user_id = df.userId.sample(1).iloc[0]
movie_watched_by_user = df[df.userId == user_id]


movie_not_watched = movie_df[~movie_df['id'].isin(movie_watched_by_user.movieId.values)]['id']
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

"""# Menampilkan Rekomendasi Film untuk Pengguna

Kode ini digunakan untuk menghasilkan rekomendasi film berdasarkan hasil prediksi model sistem rekomendasi. Proses dimulai dengan memprediksi rating untuk setiap film yang belum ditonton oleh pengguna menggunakan model.predict pada array input user_movie_array. Hasil prediksi ini kemudian diratakan dengan flatten untuk mempermudah manipulasi data. Selanjutnya, indeks dari 10 film teratas dengan prediksi rating tertinggi diambil menggunakan argsort.
"""

ratings = model.predict(user_movie_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('movie with high ratings from user')
print('----' * 8)

top_movie_user = (
    movie_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows = movie_df[movie_df['id'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.movie_name, ':', row.genre)

print('----' * 8)
print('Top 10 movie recommendation')
print('----' * 8)

recommended_movie = movie_df[movie_df['id'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.movie_name, ':', row.genre)